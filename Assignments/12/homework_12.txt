1. As described in class, modify the main function in classify.py so that it tests the question of how
    training proportion and normalization method effect test accuracy. Use the following lists:

        training_proportion_list = [.10, .20, .50, .95]
        normalize_method_list = [None, 'z-score']

    This gives us a 4x2 design with two independent variables (training proportion and normalization method) and one
    dependent variable (test accuracy).

    Add these lists to the main function, and then write a set of two loops (one inside the other) that iterate over them,
    resulting in all possible combinations of the two variables. Within these loops, write a third loop that iterates 30
    times, each time, creating a new instance of the LogisticRegression class, training the model, and testing the model.
    For each run of the model, save the accuracy (reminder hint, it is a member variable of the LogisticRegression class
    that is given it's value after the .test() method is run). keep track of the results from each run of the model, and
    after all 2*4*30 models have run, compute the means and create a 2x4 bar plot using matplotlib. Make sure you label the
    axis and create a legend! Small amount of extra credit if you figure out how to have the plot print error bars.

    A couple extra hints.
    i) Remember, all the necessary code modifications can be made to the main function in classify.py. You dont need to
    modify, or even look at, the logistic regression code if you dont want to.
    ii) I would make a copy of the lab classify.py, save it as classify_homework.py, or something like that, so that you
    have a version of the original code you can use to answer questions 3-6.
    iii) there are many ways you can keep track of the results, but the easiest way (in terms of fewest lines of code) is
    to create a 3-dimensional numpy matrix (4 x 2 x 30), store each result in a slot in that matrix, and then compute the
    mean using matrix.mean(2).


2. Interpret the results of the plot that you have produced. In particular, you should notice that there is an
interaction (i.e. the effect
of one variable depends on the level of the other variable). Describe this interaction and explain why you think it is
occurring.

3. Go back to the original, unmodified version of classify.py. Run it using the following parameters:

    RANDOM_SEED = None
    TRAINING_PROPORTION = .05
    NORMALIZE_METHOD = None
    SVD_DIM = 0
    LEARNING_RATE = 0.1
    NUM_EPOCHS = 1000
    INPUT_FILE_NAME = 'data/data3.csv'
    RANDOM_DATA = False

    Train and test the model, and observe that does pretty well, getting 98% or better on the test items almost
    every time. What has it learned? Using the data that prints out when the model is trained and tested, or using the
    data from dataset.compute_feature_correlations(), or from any of the plots that these classes can generate,
    describe what the model has learned. What features are useful in the dataset? What features is the model using?
    Try to logically describe what the model "knows" and how it is making it's decision. Pay particular attention to
    the plot generated by my_logreg.plot_weight_heat_map(), which shows the strength of the weighted connections between
    each feature and each category. You can think of these like the best fit lines in a regression equation, where x
    is the value of the feature, and y is the category that is being predicted (0 or 1 for whether that word is in
    that category). For example, if the cell for row "has feathers" is bright red for the bird column, and bright blue
    for the "mammal" column, that would mean the model thinks the feature is really predictive of a word being a bird if
    it has feathers, and really predicted of the word not being a mammal. Using this logic, what has the model learned,
    and which words, if any, does it lead to it getting wrong. If you happen to get a perfect model, rerun it a few times
    to get one that misses a few.